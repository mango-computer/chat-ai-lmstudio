#!/bin/bash

echo "ğŸš€ Starting Chat AI Backend..."
echo ""

# Check if we're in the right directory
if [ ! -f "backend/main.py" ]; then
    echo "âŒ Error: Please run this script from the client-chat directory"
    exit 1
fi

# Check if Python is installed
if ! command -v python3 &> /dev/null; then
    echo "âŒ Error: Python 3 is not installed"
    exit 1
fi

# Navigate to backend directory
cd backend

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Creating virtual environment..."
    python3 -m venv venv
fi

# Activate virtual environment
echo "ğŸ”§ Activating virtual environment..."
source venv/bin/activate

# Install dependencies
echo "ğŸ“¥ Installing dependencies..."
pip install -q -r requirements.txt

# Check if LM Studio is running
echo ""
echo "ğŸ” Checking LM Studio connection..."
if curl -s http://localhost:1234/v1/models > /dev/null 2>&1; then
    echo "âœ… LM Studio is running!"
else
    echo "âš ï¸  Warning: LM Studio doesn't appear to be running on port 1234"
    echo "   Please start LM Studio and load a model before using the chat"
fi

echo ""
echo "ğŸŒŸ Starting FastAPI server on http://localhost:8000"
echo "ğŸ“š API Documentation: http://localhost:8000/docs"
echo ""
echo "Press Ctrl+C to stop the server"
echo ""

# Start the server
uvicorn main:app --reload

